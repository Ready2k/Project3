"""Fake LLM and embedding providers for testing."""

import hashlib
from random import Random
from typing import Any, Dict, List

from app.llm.base import LLMProvider, EmbeddingProvider


class FakeLLM(LLMProvider):
    """Deterministic fake LLM for testing."""

    def __init__(self, responses: Dict[str, str], seed: int = 42):
        """Initialize fake LLM with predefined responses.

        Args:
            responses: Dict mapping prompt hashes to responses
            seed: Random seed for deterministic behavior
        """
        self.responses = responses
        self.seed = seed
        self.random = Random(seed)

    async def generate(self, prompt: str, **kwargs: Any) -> str:
        """Generate deterministic response based on prompt hash."""
        # Create deterministic hash of prompt
        prompt_hash = hashlib.md5(prompt.encode()).hexdigest()[:8]

        # Return predefined response or default
        if prompt_hash in self.responses:
            return self.responses[prompt_hash]

        # Generate deterministic default response
        self.random.seed(int(prompt_hash, 16))
        responses = [
            "This is a fake response.",
            "Generated by fake LLM.",
            "Deterministic test output.",
            "Mock LLM response.",
        ]
        return self.random.choice(responses)

    async def test_connection(self) -> bool:
        """Fake connection test always succeeds."""
        return True

    def get_model_info(self) -> Dict[str, Any]:
        """Get fake model information."""
        return {
            "provider": "fake",
            "model": "fake-llm",
            "seed": self.seed,
            "response_count": len(self.responses),
        }


class FakeLLMProvider(LLMProvider):
    """Fake LLM provider that follows the standard provider interface."""

    def __init__(
        self,
        model: str = "fake-llm",
        responses: Dict[str, str] = None,
        seed: int = 42,
        **kwargs,
    ):
        """Initialize fake LLM provider.

        Args:
            model: Model name for identification
            responses: Dict mapping prompt hashes to responses
            seed: Random seed for deterministic behavior
            **kwargs: Additional configuration (ignored)
        """
        self.model = model
        self.responses = responses or {}
        self.seed = seed
        self.random = Random(seed)
        self.last_tokens_used = None

    async def generate(self, prompt: str, **kwargs: Any) -> str:
        """Generate deterministic response based on prompt hash."""
        # Create deterministic hash of prompt
        prompt_hash = hashlib.md5(prompt.encode()).hexdigest()[:8]

        # Return predefined response or default
        if prompt_hash in self.responses:
            response = self.responses[prompt_hash]
        else:
            # Generate deterministic default response
            self.random.seed(int(prompt_hash, 16))
            responses = [
                f"This is a fake response to: {prompt[:50]}...",
                f"Generated by fake LLM model {self.model}.",
                f"Deterministic test output for prompt hash {prompt_hash}.",
                f"Mock LLM response with seed {self.seed}.",
            ]
            response = self.random.choice(responses)

        # Simulate token usage
        self.last_tokens_used = len(prompt.split()) + len(response.split())

        return response

    async def test_connection(self) -> bool:
        """Fake connection test always succeeds."""
        return True

    def get_model_info(self) -> Dict[str, Any]:
        """Get fake model information."""
        return {
            "provider": "fake",
            "model": self.model,
            "seed": self.seed,
            "response_count": len(self.responses),
            "api_key_set": True,  # Always true for fake provider
        }

    async def get_available_models(self) -> List[Dict[str, Any]]:
        """Get fake available models."""
        return [
            {
                "id": "fake-llm",
                "name": "Fake LLM",
                "description": "Deterministic fake LLM for testing",
                "context_length": 4096,
                "capabilities": ["text_generation", "testing"],
            },
            {
                "id": "fake-llm-large",
                "name": "Fake LLM Large",
                "description": "Large fake LLM for testing",
                "context_length": 8192,
                "capabilities": ["text_generation", "testing", "large_context"],
            },
        ]


class FakeEmbedder(EmbeddingProvider):
    """Deterministic fake embedder for testing."""

    def __init__(self, dimension: int = 384, seed: int = 42):
        """Initialize fake embedder.

        Args:
            dimension: Embedding dimension
            seed: Random seed for deterministic behavior
        """
        self.dimension = dimension
        self.seed = seed
        self.random = Random(seed)

    async def embed(self, text: str) -> List[float]:
        """Generate deterministic embedding based on text hash."""
        # Create deterministic hash of text
        text_hash = hashlib.md5(text.encode()).hexdigest()

        # Use hash to seed random generator
        self.random.seed(int(text_hash[:8], 16))

        # Generate deterministic embedding
        return [self.random.gauss(0, 1) for _ in range(self.dimension)]

    async def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """Generate embeddings for multiple texts."""
        embeddings = []
        for text in texts:
            embedding = await self.embed(text)
            embeddings.append(embedding)
        return embeddings
